{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585ef301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c9060",
   "metadata": {},
   "source": [
    "### Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54acfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/videos_featured.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48796e",
   "metadata": {},
   "source": [
    "### Step 2: Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1b24e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>tags</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>published_us_est</th>\n",
       "      <th>published_year</th>\n",
       "      <th>published_month</th>\n",
       "      <th>published_quarter</th>\n",
       "      <th>published_weekday</th>\n",
       "      <th>published_hour</th>\n",
       "      <th>like_ratio</th>\n",
       "      <th>comment_ratio</th>\n",
       "      <th>publish_time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGC0cCAgGu0</td>\n",
       "      <td>Twitter making me tear up over here ðŸ¥¹</td>\n",
       "      <td>2024-02-23 13:34:27</td>\n",
       "      <td>7502</td>\n",
       "      <td>305</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>16</td>\n",
       "      <td>2024-02-23 08:34:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UOBTLzWY1vs</td>\n",
       "      <td>#DataAnalyst #AnalystBuilder #SQL</td>\n",
       "      <td>2024-03-01 13:43:29</td>\n",
       "      <td>21921</td>\n",
       "      <td>1515</td>\n",
       "      <td>20</td>\n",
       "      <td>[]</td>\n",
       "      <td>38</td>\n",
       "      <td>2024-03-01 08:43:29</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k8nBWL6K884</td>\n",
       "      <td>What is Healthcare Analytics?</td>\n",
       "      <td>2025-02-18 13:01:11</td>\n",
       "      <td>26399</td>\n",
       "      <td>1303</td>\n",
       "      <td>79</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>656</td>\n",
       "      <td>2025-02-18 08:01:11</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r5512UY3MTc</td>\n",
       "      <td>1 Million Subscriber Livestream!! Giveaways + ...</td>\n",
       "      <td>2025-03-05 17:07:10</td>\n",
       "      <td>10268</td>\n",
       "      <td>675</td>\n",
       "      <td>68</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>6014</td>\n",
       "      <td>2025-03-05 12:07:10</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XuOcmjIbFGg</td>\n",
       "      <td>Taking a look at Real Healthcare Data | ICD11,...</td>\n",
       "      <td>2025-03-04 13:00:44</td>\n",
       "      <td>8534</td>\n",
       "      <td>402</td>\n",
       "      <td>27</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>916</td>\n",
       "      <td>2025-03-04 08:00:44</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  FGC0cCAgGu0              Twitter making me tear up over here ðŸ¥¹   \n",
       "1  UOBTLzWY1vs                  #DataAnalyst #AnalystBuilder #SQL   \n",
       "2  k8nBWL6K884                      What is Healthcare Analytics?   \n",
       "3  r5512UY3MTc  1 Million Subscriber Livestream!! Giveaways + ...   \n",
       "4  XuOcmjIbFGg  Taking a look at Real Healthcare Data | ICD11,...   \n",
       "\n",
       "          published_at  views  likes  comments  \\\n",
       "0  2024-02-23 13:34:27   7502    305        12   \n",
       "1  2024-03-01 13:43:29  21921   1515        20   \n",
       "2  2025-02-18 13:01:11  26399   1303        79   \n",
       "3  2025-03-05 17:07:10  10268    675        68   \n",
       "4  2025-03-04 13:00:44   8534    402        27   \n",
       "\n",
       "                                                tags  duration_seconds  \\\n",
       "0                                                 []                16   \n",
       "1                                                 []                38   \n",
       "2  ['Data Analyst', 'Data Analyst job', 'Data Ana...               656   \n",
       "3  ['Data Analyst', 'Data Analyst job', 'Data Ana...              6014   \n",
       "4  ['Data Analyst', 'Data Analyst job', 'Data Ana...               916   \n",
       "\n",
       "      published_us_est  published_year  published_month published_quarter  \\\n",
       "0  2024-02-23 08:34:27            2024                2                Q1   \n",
       "1  2024-03-01 08:43:29            2024                3                Q1   \n",
       "2  2025-02-18 08:01:11            2025                2                Q1   \n",
       "3  2025-03-05 12:07:10            2025                3                Q1   \n",
       "4  2025-03-04 08:00:44            2025                3                Q1   \n",
       "\n",
       "  published_weekday  published_hour  like_ratio  comment_ratio  \\\n",
       "0            Friday               8      0.0407         0.0016   \n",
       "1            Friday               8      0.0691         0.0009   \n",
       "2           Tuesday               8      0.0494         0.0030   \n",
       "3         Wednesday              12      0.0657         0.0066   \n",
       "4           Tuesday               8      0.0471         0.0032   \n",
       "\n",
       "  publish_time_of_day  \n",
       "0             Morning  \n",
       "1             Morning  \n",
       "2             Morning  \n",
       "3           Afternoon  \n",
       "4             Morning  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # View top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a276401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Check the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320afb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'title', 'published_at', 'views', 'likes', 'comments',\n",
       "       'tags', 'duration_seconds', 'published_us_est', 'published_year',\n",
       "       'published_month', 'published_quarter', 'published_weekday',\n",
       "       'published_hour', 'like_ratio', 'comment_ratio', 'publish_time_of_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012275d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                object\n",
       "title                   object\n",
       "published_at            object\n",
       "views                    int64\n",
       "likes                    int64\n",
       "comments                 int64\n",
       "tags                    object\n",
       "duration_seconds         int64\n",
       "published_us_est        object\n",
       "published_year           int64\n",
       "published_month          int64\n",
       "published_quarter       object\n",
       "published_weekday       object\n",
       "published_hour           int64\n",
       "like_ratio             float64\n",
       "comment_ratio          float64\n",
       "publish_time_of_day     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # Check data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89c59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   video_id             366 non-null    object \n",
      " 1   title                366 non-null    object \n",
      " 2   published_at         366 non-null    object \n",
      " 3   views                366 non-null    int64  \n",
      " 4   likes                366 non-null    int64  \n",
      " 5   comments             366 non-null    int64  \n",
      " 6   tags                 366 non-null    object \n",
      " 7   duration_seconds     366 non-null    int64  \n",
      " 8   published_us_est     366 non-null    object \n",
      " 9   published_year       366 non-null    int64  \n",
      " 10  published_month      366 non-null    int64  \n",
      " 11  published_quarter    366 non-null    object \n",
      " 12  published_weekday    366 non-null    object \n",
      " 13  published_hour       366 non-null    int64  \n",
      " 14  like_ratio           366 non-null    float64\n",
      " 15  comment_ratio        366 non-null    float64\n",
      " 16  publish_time_of_day  366 non-null    object \n",
      "dtypes: float64(2), int64(7), object(8)\n",
      "memory usage: 48.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Check nulls + types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a862da",
   "metadata": {},
   "source": [
    "### Step 3: Metrics Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b239ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all date time to UTC time zone\n",
    "df['published_at'] = pd.to_datetime(df['published_at'], utc=True)\n",
    "today = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "# Normalize metrics\n",
    "df['days_since_publish'] = (today - df['published_at']).dt.days.clip(lower=1) # type: ignore # ensure the minimal day is 1\n",
    "df['views_per_day'] = df['views']/df['days_since_publish']\n",
    "df['likes_per_day'] = df['likes']/df['days_since_publish']\n",
    "\n",
    "\n",
    "# Label duration buckets\n",
    "df['duration_bucket'] = pd.cut(df['duration_seconds'], \n",
    "    bins=[0, 600, 1800, 3600, 100000],\n",
    "    labels=['Short', 'Medium', 'Long', 'Very Long']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d76c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   video_id             366 non-null    object             \n",
      " 1   title                366 non-null    object             \n",
      " 2   published_at         366 non-null    datetime64[ns, UTC]\n",
      " 3   views                366 non-null    int64              \n",
      " 4   likes                366 non-null    int64              \n",
      " 5   comments             366 non-null    int64              \n",
      " 6   tags                 366 non-null    object             \n",
      " 7   duration_seconds     366 non-null    int64              \n",
      " 8   published_us_est     366 non-null    object             \n",
      " 9   published_year       366 non-null    int64              \n",
      " 10  published_month      366 non-null    int64              \n",
      " 11  published_quarter    366 non-null    object             \n",
      " 12  published_weekday    366 non-null    object             \n",
      " 13  published_hour       366 non-null    int64              \n",
      " 14  like_ratio           366 non-null    float64            \n",
      " 15  comment_ratio        366 non-null    float64            \n",
      " 16  publish_time_of_day  366 non-null    object             \n",
      " 17  days_since_publish   366 non-null    int64              \n",
      " 18  views_per_day        366 non-null    float64            \n",
      " 19  likes_per_day        366 non-null    float64            \n",
      " 20  duration_bucket      366 non-null    category           \n",
      "dtypes: category(1), datetime64[ns, UTC](1), float64(4), int64(8), object(7)\n",
      "memory usage: 57.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6383fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>tags</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>published_us_est</th>\n",
       "      <th>published_year</th>\n",
       "      <th>...</th>\n",
       "      <th>published_quarter</th>\n",
       "      <th>published_weekday</th>\n",
       "      <th>published_hour</th>\n",
       "      <th>like_ratio</th>\n",
       "      <th>comment_ratio</th>\n",
       "      <th>publish_time_of_day</th>\n",
       "      <th>days_since_publish</th>\n",
       "      <th>views_per_day</th>\n",
       "      <th>likes_per_day</th>\n",
       "      <th>duration_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGC0cCAgGu0</td>\n",
       "      <td>Twitter making me tear up over here ðŸ¥¹</td>\n",
       "      <td>2024-02-23 13:34:27+00:00</td>\n",
       "      <td>7502</td>\n",
       "      <td>305</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>16</td>\n",
       "      <td>2024-02-23 08:34:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>Morning</td>\n",
       "      <td>509</td>\n",
       "      <td>14.738703</td>\n",
       "      <td>0.599214</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UOBTLzWY1vs</td>\n",
       "      <td>#DataAnalyst #AnalystBuilder #SQL</td>\n",
       "      <td>2024-03-01 13:43:29+00:00</td>\n",
       "      <td>21921</td>\n",
       "      <td>1515</td>\n",
       "      <td>20</td>\n",
       "      <td>[]</td>\n",
       "      <td>38</td>\n",
       "      <td>2024-03-01 08:43:29</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Morning</td>\n",
       "      <td>502</td>\n",
       "      <td>43.667331</td>\n",
       "      <td>3.017928</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k8nBWL6K884</td>\n",
       "      <td>What is Healthcare Analytics?</td>\n",
       "      <td>2025-02-18 13:01:11+00:00</td>\n",
       "      <td>26399</td>\n",
       "      <td>1303</td>\n",
       "      <td>79</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>656</td>\n",
       "      <td>2025-02-18 08:01:11</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>Morning</td>\n",
       "      <td>148</td>\n",
       "      <td>178.371622</td>\n",
       "      <td>8.804054</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r5512UY3MTc</td>\n",
       "      <td>1 Million Subscriber Livestream!! Giveaways + ...</td>\n",
       "      <td>2025-03-05 17:07:10+00:00</td>\n",
       "      <td>10268</td>\n",
       "      <td>675</td>\n",
       "      <td>68</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>6014</td>\n",
       "      <td>2025-03-05 12:07:10</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>133</td>\n",
       "      <td>77.203008</td>\n",
       "      <td>5.075188</td>\n",
       "      <td>Very Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XuOcmjIbFGg</td>\n",
       "      <td>Taking a look at Real Healthcare Data | ICD11,...</td>\n",
       "      <td>2025-03-04 13:00:44+00:00</td>\n",
       "      <td>8534</td>\n",
       "      <td>402</td>\n",
       "      <td>27</td>\n",
       "      <td>['Data Analyst', 'Data Analyst job', 'Data Ana...</td>\n",
       "      <td>916</td>\n",
       "      <td>2025-03-04 08:00:44</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Morning</td>\n",
       "      <td>134</td>\n",
       "      <td>63.686567</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  FGC0cCAgGu0              Twitter making me tear up over here ðŸ¥¹   \n",
       "1  UOBTLzWY1vs                  #DataAnalyst #AnalystBuilder #SQL   \n",
       "2  k8nBWL6K884                      What is Healthcare Analytics?   \n",
       "3  r5512UY3MTc  1 Million Subscriber Livestream!! Giveaways + ...   \n",
       "4  XuOcmjIbFGg  Taking a look at Real Healthcare Data | ICD11,...   \n",
       "\n",
       "               published_at  views  likes  comments  \\\n",
       "0 2024-02-23 13:34:27+00:00   7502    305        12   \n",
       "1 2024-03-01 13:43:29+00:00  21921   1515        20   \n",
       "2 2025-02-18 13:01:11+00:00  26399   1303        79   \n",
       "3 2025-03-05 17:07:10+00:00  10268    675        68   \n",
       "4 2025-03-04 13:00:44+00:00   8534    402        27   \n",
       "\n",
       "                                                tags  duration_seconds  \\\n",
       "0                                                 []                16   \n",
       "1                                                 []                38   \n",
       "2  ['Data Analyst', 'Data Analyst job', 'Data Ana...               656   \n",
       "3  ['Data Analyst', 'Data Analyst job', 'Data Ana...              6014   \n",
       "4  ['Data Analyst', 'Data Analyst job', 'Data Ana...               916   \n",
       "\n",
       "      published_us_est  published_year  ...  published_quarter  \\\n",
       "0  2024-02-23 08:34:27            2024  ...                 Q1   \n",
       "1  2024-03-01 08:43:29            2024  ...                 Q1   \n",
       "2  2025-02-18 08:01:11            2025  ...                 Q1   \n",
       "3  2025-03-05 12:07:10            2025  ...                 Q1   \n",
       "4  2025-03-04 08:00:44            2025  ...                 Q1   \n",
       "\n",
       "  published_weekday published_hour  like_ratio  comment_ratio  \\\n",
       "0            Friday              8      0.0407         0.0016   \n",
       "1            Friday              8      0.0691         0.0009   \n",
       "2           Tuesday              8      0.0494         0.0030   \n",
       "3         Wednesday             12      0.0657         0.0066   \n",
       "4           Tuesday              8      0.0471         0.0032   \n",
       "\n",
       "   publish_time_of_day days_since_publish  views_per_day  likes_per_day  \\\n",
       "0              Morning                509      14.738703       0.599214   \n",
       "1              Morning                502      43.667331       3.017928   \n",
       "2              Morning                148     178.371622       8.804054   \n",
       "3            Afternoon                133      77.203008       5.075188   \n",
       "4              Morning                134      63.686567       3.000000   \n",
       "\n",
       "   duration_bucket  \n",
       "0            Short  \n",
       "1            Short  \n",
       "2           Medium  \n",
       "3        Very Long  \n",
       "4           Medium  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240c595",
   "metadata": {},
   "source": [
    "### Step 4: Descriptive Statistics\n",
    "#### Statistics for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049e61ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>published_year</th>\n",
       "      <th>published_month</th>\n",
       "      <th>published_hour</th>\n",
       "      <th>like_ratio</th>\n",
       "      <th>comment_ratio</th>\n",
       "      <th>days_since_publish</th>\n",
       "      <th>views_per_day</th>\n",
       "      <th>likes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.660000e+02</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>366.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.390425e+05</td>\n",
       "      <td>3328.486339</td>\n",
       "      <td>180.199454</td>\n",
       "      <td>1700.691257</td>\n",
       "      <td>2022.297814</td>\n",
       "      <td>6.327869</td>\n",
       "      <td>8.341530</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>1006.745902</td>\n",
       "      <td>152.360931</td>\n",
       "      <td>3.926950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.597877e+05</td>\n",
       "      <td>5760.090393</td>\n",
       "      <td>385.038146</td>\n",
       "      <td>4786.842221</td>\n",
       "      <td>1.570741</td>\n",
       "      <td>3.537144</td>\n",
       "      <td>2.555847</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>567.570341</td>\n",
       "      <td>295.711148</td>\n",
       "      <td>8.185501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.590000e+02</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.955368</td>\n",
       "      <td>0.056117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.292150e+04</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>386.250000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>554.250000</td>\n",
       "      <td>19.355626</td>\n",
       "      <td>0.682722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.568100e+04</td>\n",
       "      <td>1332.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>721.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>935.500000</td>\n",
       "      <td>56.557802</td>\n",
       "      <td>1.840762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.397555e+05</td>\n",
       "      <td>3597.750000</td>\n",
       "      <td>161.750000</td>\n",
       "      <td>1581.500000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>1554.500000</td>\n",
       "      <td>168.235426</td>\n",
       "      <td>4.225069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.174630e+06</td>\n",
       "      <td>48329.000000</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>84768.000000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>109.399083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              views         likes     comments  duration_seconds  \\\n",
       "count  3.660000e+02    366.000000   366.000000        366.000000   \n",
       "mean   1.390425e+05   3328.486339   180.199454       1700.691257   \n",
       "std    2.597877e+05   5760.090393   385.038146       4786.842221   \n",
       "min    2.590000e+02     34.000000     3.000000          9.000000   \n",
       "25%    1.292150e+04    435.000000    30.000000        386.250000   \n",
       "50%    3.568100e+04   1332.500000    77.000000        721.000000   \n",
       "75%    1.397555e+05   3597.750000   161.750000       1581.500000   \n",
       "max    2.174630e+06  48329.000000  4370.000000      84768.000000   \n",
       "\n",
       "       published_year  published_month  published_hour  like_ratio  \\\n",
       "count      366.000000       366.000000      366.000000  366.000000   \n",
       "mean      2022.297814         6.327869        8.341530    0.033302   \n",
       "std          1.570741         3.537144        2.555847    0.016346   \n",
       "min       2020.000000         1.000000        0.000000    0.012000   \n",
       "25%       2021.000000         3.000000        7.000000    0.021825   \n",
       "50%       2022.000000         6.000000        8.000000    0.029550   \n",
       "75%       2024.000000         9.750000        9.000000    0.039300   \n",
       "max       2025.000000        12.000000       23.000000    0.131300   \n",
       "\n",
       "       comment_ratio  days_since_publish  views_per_day  likes_per_day  \n",
       "count     366.000000          366.000000     366.000000     366.000000  \n",
       "mean        0.003144         1006.745902     152.360931       3.926950  \n",
       "std         0.005271          567.570341     295.711148       8.185501  \n",
       "min         0.000200           29.000000       0.955368       0.056117  \n",
       "25%         0.000800          554.250000      19.355626       0.682722  \n",
       "50%         0.001600          935.500000      56.557802       1.840762  \n",
       "75%         0.003175         1554.500000     168.235426       4.225069  \n",
       "max         0.063800         2007.000000    2560.000000     109.399083  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # Summary for numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42312c9c",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "- Huge difference between **mean** and **median**-> strong right skew in `views` and `likes`\n",
    "- `comments` also skewed\n",
    "- Outliers are pulling the average up\n",
    "- Maximum of duration(84,768 s, about 23.5 hrs!) suggests at least one extremely long video\n",
    "- Most videos published between morning hours\n",
    "\n",
    "#### Suggestions:\n",
    "- Use **log scale** when visualizing `views` and `likes`\n",
    "- Bin durations into categories: Short, Medium, Long, Very Long\n",
    "- Consider remove extreme values\n",
    "- User `views_per_day` and `likes_per_day` for grouped trend analyses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdae8ea",
   "metadata": {},
   "source": [
    "#### Statistics for non-numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c994e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Video Count  % of Total\n",
      "published_weekday                         \n",
      "Monday                      19         5.2\n",
      "Tuesday                    238        65.0\n",
      "Wednesday                   28         7.7\n",
      "Thursday                    55        15.0\n",
      "Friday                      17         4.6\n",
      "Saturday                     6         1.6\n",
      "Sunday                       3         0.8\n"
     ]
    }
   ],
   "source": [
    "weekday_counts = df['published_weekday'].value_counts() # Published total videos of each weekday\n",
    "weekday_summary = pd.DataFrame(\n",
    "    {'Video Count': weekday_counts,\n",
    "     '% of Total': (weekday_counts/weekday_counts.sum()*100).round(1)        \n",
    "    }\n",
    ")\n",
    "\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_summary = weekday_summary.reindex(weekday_order)\n",
    "\n",
    "print(weekday_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e237ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Video_count  % of Total\n",
      "published_hour                         \n",
      "0                         2         0.5\n",
      "6                        50        13.7\n",
      "7                        88        24.0\n",
      "8                       128        35.0\n",
      "9                        23         6.3\n",
      "10                       24         6.6\n",
      "11                       19         5.2\n",
      "12                       19         5.2\n",
      "13                        4         1.1\n",
      "14                        2         0.5\n",
      "19                        1         0.3\n",
      "21                        3         0.8\n",
      "22                        2         0.5\n",
      "23                        1         0.3\n"
     ]
    }
   ],
   "source": [
    "hour_counts = df['published_hour'].value_counts() # Published total videos of each hour\n",
    "hour_summary = pd.DataFrame(\n",
    "    {'Video_count':hour_counts,\n",
    "     '% of Total': (hour_counts/hour_counts.sum()*100).round(1)        \n",
    "    }\n",
    ")\n",
    "\n",
    "hour_order = [0,6,7,8,9,10,11,12,13,14,19,21,22,23]\n",
    "hour_summary = hour_summary.reindex(hour_order)\n",
    "\n",
    "print(hour_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccec9c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'published_time_of_day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'published_time_of_day'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m daytime_counts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublished_time_of_day\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts() \u001b[38;5;66;03m# Published total videos of each time of day\u001b[39;00m\n\u001b[0;32m      2\u001b[0m daytime_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo_counts\u001b[39m\u001b[38;5;124m'\u001b[39m: daytime_counts,\n\u001b[0;32m      4\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[38;5;124mf Total\u001b[39m\u001b[38;5;124m'\u001b[39m: (daytime_counts\u001b[38;5;241m/\u001b[39mdaytime_counts\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m         \n\u001b[0;32m      6\u001b[0m     }\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m daytime_order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEarly Morning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMorning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfternoon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvening\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'published_time_of_day'"
     ]
    }
   ],
   "source": [
    "daytime_counts = df['published_time_of_day'].value_counts() # Published total videos of each time of day\n",
    "daytime_summary = pd.DataFrame(\n",
    "    {'Video_counts': daytime_counts,\n",
    "     '% of Total': (daytime_counts/daytime_counts.sum()*100).round(1)\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "daytime_order = ['Early Morning', 'Morning', 'Afternoon', 'Evening']\n",
    "daytime_summary = daytime_summary.reindex(daytime_order)\n",
    "\n",
    "print(daytime_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e08c2e",
   "metadata": {},
   "source": [
    "### Step 4: Visualize Distributions and Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Views distribution\n",
    "sns.histplot(df['views_per_day'], bins=50) # type: ignore\n",
    "plt.title(\"Distribution of Views\")\n",
    "plt.xlabel('Views per Day')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4779192",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "- **Majority of Low Views**: A substantial portion of the data points fall into the lowest view categories. For example, over 175 items have very few views per day, and roughly 70 have slightly more (perhaps up to 100-150 views/day).\n",
    "\n",
    "- **Decreasing Frequency**: As the number of views per day increases, the frequency of items with that many views rapidly decreases.\n",
    "\n",
    "- **Rare High Performers**: Only a very small number of items achieve high view counts. For instance, there are only a handful of items with views between 500 and 1000 per day, and even fewer above 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize = (14,7))\n",
    "\n",
    "# Boxplot of views by weekday\n",
    "weekday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(x='published_weekday', y='views_per_day', data=df, order = weekday, showfliers=True, width=0.5,ax=axes[0],\n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "axes[0].set_ylabel('Views per Day')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].set_xlabel('Published weekday')\n",
    "axes[0].set_title(\"Views along Published Weekday\")\n",
    "\n",
    "\n",
    "# Barplot of the views distribution along weekday\n",
    "sns.countplot(x='published_weekday', data=df, order=weekday, ax=axes[1])\n",
    "for p in axes[1].patches:\n",
    "    count = int(p.get_height())\n",
    "    axes[1].text(p.get_x() + p.get_width() / 2,\n",
    "                 p.get_height() + 1,\n",
    "                 str(count),\n",
    "                 ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "axes[1].set_ylabel('Total Videos')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].set_xlabel('Published Weekday')\n",
    "axes[1].set_title(\"Total Videos along Published Weekday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e332ee",
   "metadata": {},
   "source": [
    "**Insights**: \n",
    "- Tuesday videos tend to perform more consistently well. \n",
    "- Monday, Wednesday, Thursday and Friday all have a high median.\n",
    "- Saturday is consistently underperforming.\n",
    "- Sunday performs better than Saturday, but still has a low median views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize = (14,7))\n",
    "\n",
    "day_of_time=['Early Morning', 'Morning', 'Afternoon', 'Evening']\n",
    "\n",
    "# Distribution of  views per day by time of day\n",
    "sns.boxplot(x='published_time_of_day', y='views_per_day', data=df, order=day_of_time, width=0.4, ax=axes[0],\n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "\n",
    "axes[0].set_ylabel('Views per Day')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].set_xlabel('Published Day of Time')\n",
    "axes[0].set_title(\"Views per Day along Published Day of Time\")\n",
    "\n",
    "\n",
    "\n",
    "# Barplot of the views distribution along weekday\n",
    "sns.countplot(x='published_time_of_day', data=df, order=day_of_time, ax=axes[1])\n",
    "\n",
    "for p in axes[1].patches:\n",
    "    count = int(p.get_height())\n",
    "    axes[1].text(p.get_x() + p.get_width() / 2,\n",
    "                 p.get_height() + 1,\n",
    "                 str(count),\n",
    "                 ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "\n",
    "\n",
    "axes[1].set_ylabel('Total videos')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].set_xlabel('Published Day of Time')\n",
    "axes[1].set_title(\"Total Videos along Published Day of Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize = (14,7))\n",
    "\n",
    "# Boxplot of views by weekday\n",
    "weekday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(x='published_weekday', y='likes_per_day', data=df, order = weekday, showfliers=True, width=0.5,ax=axes[0],\n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "axes[0].set_ylabel('Likes per Day')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].set_xlabel('Published weekday')\n",
    "axes[0].set_title(\"Likes per Day along Published Weekday\")\n",
    "\n",
    "\n",
    "day_of_time=['Early Morning', 'Morning', 'Afternoon', 'Evening']\n",
    "\n",
    "# Distribution of  views per day by time of day\n",
    "sns.boxplot(x='published_time_of_day', y='likes_per_day', data=df, order=day_of_time, width=0.4, ax=axes[1],\n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "\n",
    "axes[1].set_ylabel('Likes per Day')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].set_xlabel('Published Day of Time')\n",
    "axes[1].set_title(\"Likes per Day along Published Day of Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['duration_seconds'], bins=50) # type: ignore\n",
    "plt.title(\"Distribution of Duration\")\n",
    "plt.xlabel('Duration in Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484fb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define duration buckets\n",
    "fig, axes=plt.subplots()\n",
    "\n",
    "df['duration_bucket'] = pd.cut(\n",
    "    df['duration_seconds'],\n",
    "    bins=[0, 600, 1800, 3600, 100000],\n",
    "    labels=['Short (0-10 min)', 'Medium (10-30 min)', 'Long (30-60 min)', 'Very Long (60+ min)'],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Plot duration distribution\n",
    "sns.countplot(x='duration_bucket', data=df, ax=axes)  # Use countplot for category frequencies\n",
    "\n",
    "for p in axes.patches:\n",
    "    count = int(p.get_height())\n",
    "    axes.text(p.get_x() + p.get_width() / 2,\n",
    "                 p.get_height() + 1,\n",
    "                 str(count),\n",
    "                 ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "\n",
    "plt.title(\"Distribution of Video Duration Categories\")\n",
    "plt.xlabel(\"Duration Category\")\n",
    "plt.ylabel(\"Number of Videos\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='duration_bucket', y='views_per_day', data=df, estimator='mean')\n",
    "plt.title(\"Average Views per Day by Video Duration\")\n",
    "plt.xlabel(\"Duration Category\")\n",
    "plt.xticks(rotation=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like ratio vs duration\n",
    "sns.boxplot(x='duration_bucket', y='views_per_day', data=df, width=0.4, \n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Duration Categories')\n",
    "plt.ylabel('Views per Day')\n",
    "plt.xticks(rotation=15)\n",
    "plt.title(\"Video Duration vs Views per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='duration_bucket', y='likes_per_day', data=df, estimator='mean')\n",
    "plt.title(\"Average Likes per Day by Video Duration\")\n",
    "plt.xlabel(\"Duration Category\")\n",
    "plt.xticks(rotation=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='duration_bucket', y='likes_per_day', data=df, width=0.4, \n",
    "            boxprops=dict(facecolor='gray', edgecolor='black'),\n",
    "            medianprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Duration Categories')\n",
    "plt.ylabel('Likes per Day')\n",
    "plt.xticks(rotation=15)\n",
    "plt.title(\"Video Duration vs Likes per Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c60cc9",
   "metadata": {},
   "source": [
    "#### Step 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def clean_tags(tag_string):\n",
    "    try:\n",
    "        # Replace curly braces with brackets and parse as JSON list\n",
    "        json_compatible = tag_string.replace('{', '[').replace('}', ']')\n",
    "        return json.loads(json_compatible)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing: {tag_string} â€” {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df['tags_clean'] = df['tags_array'].apply(clean_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
